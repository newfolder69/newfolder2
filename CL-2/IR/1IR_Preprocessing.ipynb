{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4345208d-60a7-4e13-a1bd-b83840d7e270",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing necessary libraries\n",
    "import nltk  # Natural Language Toolkit for text processing\n",
    "from nltk.corpus import stopwords  # Stop words list\n",
    "from nltk.stem import PorterStemmer  # Stemmer for reducing words to their root form\n",
    "from nltk.tokenize import word_tokenize #To tokanize words\n",
    "import string  # To handle punctuation\n",
    "import re  # Regular expressions for text cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a6b21271-6aea-4f37-a0db-f3b5ce8cb475",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     C:\\Users\\ADMIN\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers\\punkt_tab.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Extra\n",
    "# Import WordNetLemmatizer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import wordnet\n",
    "\n",
    "# Download WordNet (only needed once)\n",
    "#nltk.download('wordnet')\n",
    "#nltk.download('omw-1.4')\n",
    "nltk.download('punkt_tab')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b3b2b037-f4bf-4e5a-8f2e-267eff8eb2b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\ADMIN\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping corpora\\stopwords.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Download stop words (only needed once)\n",
    "#nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "df6cf5b4-365e-4eb6-b683-131dac369407",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Load the text document\n",
    "# In this example, we assume you have a text file named 'document.txt' in the same directory as this notebook\n",
    "# Replace 'document.txt' with the path to your file if it's located elsewhere\n",
    "\n",
    "def load_text(file_path):\n",
    "    \"\"\"\n",
    "    This function reads the text from the specified file.\n",
    "    :param file_path: The path to the text file\n",
    "    :return: Text content as a string\n",
    "    \"\"\"\n",
    "    with open('1document.txt', 'r') as file:\n",
    "        text = file.read()\n",
    "        print('Document Loaded')\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2d36e2a3-bdee-46f7-9599-4471978e0a12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document Loaded\n",
      "Original Text:\n",
      " In a bustling city, people move through their daily routines, often unaware of the world unfolding around them. \n",
      "From early morning coffee shops to late-night diners, the rhythm of life continues. \n",
      "Street vendors call out, advertising fresh produce and handmade goods, while commuters rush past, eyes glued to their phones. \n",
      "In the midst of this fast-paced world, small moments of kindness often go unnoticedâ€”a smile between strangers, \n",
      "a helping hand with groceries, or a nod to a familiar face. These quiet, fleeting interactions remind us that even in the busiest environments, connection is always possible.\n"
     ]
    }
   ],
   "source": [
    "# Load the text\n",
    "text = load_text('document.txt')\n",
    "print(\"Original Text:\\n\", text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b30b322f-fd4c-4d91-ad87-660f9fd9922c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Text Preprocessing\n",
    "# We'll create a function that takes in a text and processes it by removing punctuation, lowercasing,\n",
    "# removing stop words, and applying stemming.\n",
    "\n",
    "def preprocess_text(text):\n",
    "    \"\"\"\n",
    "    This function preprocesses the input text by:\n",
    "    - Converting to lowercase\n",
    "    - Removing punctuation\n",
    "    - Removing stop words\n",
    "    - Applying stemming\n",
    "    :param text: The original text\n",
    "    :return: Processed text as a list of words\n",
    "    \"\"\"\n",
    "    # Initialize Porter Stemmer\n",
    "    stemmer = PorterStemmer()\n",
    "    \n",
    "    # Convert text to lowercase\n",
    "    text = text.lower()\n",
    "    print('\\n Text converted to lower:',text)\n",
    "    \n",
    "    # Remove punctuation using regex\n",
    "    text = re.sub(f'[{string.punctuation}]', '', text)\n",
    "    print('\\n Removed Punctuation:',text)\n",
    "    \n",
    "    #Split the text into words (tokenization)\n",
    "    #words = text.split()\n",
    "    \n",
    "    # Tokenize text (split into words)\n",
    "    words = word_tokenize(text)\n",
    "    print('\\n Tokanized words:',text)\n",
    "    \n",
    "    # Load stop words\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    \n",
    "    # Remove stop words and apply stemming\n",
    "    processed_words = [stemmer.stem(word) for word in words if word not in stop_words]\n",
    "    \n",
    "    return processed_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "108c41fd-f31f-43a7-be46-303799b276bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize WordNetLemmatizer\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "# Function to perform lemmatization on the processed words\n",
    "def lemmatize_words(words):\n",
    "    \"\"\"\n",
    "    This function applies lemmatization to a list of words.\n",
    "    :param words: List of words to lemmatize\n",
    "    :return: List of lemmatized words\n",
    "    \"\"\"\n",
    "    lemmatized_words = [lemmatizer.lemmatize(word) for word in words]\n",
    "    return lemmatized_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "55a9184c-d63e-495a-96e7-00634ece3899",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Text converted to lower: in a bustling city, people move through their daily routines, often unaware of the world unfolding around them. \n",
      "from early morning coffee shops to late-night diners, the rhythm of life continues. \n",
      "street vendors call out, advertising fresh produce and handmade goods, while commuters rush past, eyes glued to their phones. \n",
      "in the midst of this fast-paced world, small moments of kindness often go unnoticedâ€”a smile between strangers, \n",
      "a helping hand with groceries, or a nod to a familiar face. these quiet, fleeting interactions remind us that even in the busiest environments, connection is always possible.\n",
      "\n",
      " Removed Punctuation: in a bustling city people move through their daily routines often unaware of the world unfolding around them \n",
      "from early morning coffee shops to latenight diners the rhythm of life continues \n",
      "street vendors call out advertising fresh produce and handmade goods while commuters rush past eyes glued to their phones \n",
      "in the midst of this fastpaced world small moments of kindness often go unnoticedâ€”a smile between strangers \n",
      "a helping hand with groceries or a nod to a familiar face these quiet fleeting interactions remind us that even in the busiest environments connection is always possible\n",
      "\n",
      " Tokanized words: in a bustling city people move through their daily routines often unaware of the world unfolding around them \n",
      "from early morning coffee shops to latenight diners the rhythm of life continues \n",
      "street vendors call out advertising fresh produce and handmade goods while commuters rush past eyes glued to their phones \n",
      "in the midst of this fastpaced world small moments of kindness often go unnoticedâ€”a smile between strangers \n",
      "a helping hand with groceries or a nod to a familiar face these quiet fleeting interactions remind us that even in the busiest environments connection is always possible\n",
      "\n",
      "Processed Text:\n",
      " ['bustl', 'citi', 'peopl', 'move', 'daili', 'routin', 'often', 'unawar', 'world', 'unfold', 'around', 'earli', 'morn', 'coffe', 'shop', 'latenight', 'diner', 'rhythm', 'life', 'continu', 'street', 'vendor', 'call', 'advertis', 'fresh', 'produc', 'handmad', 'good', 'commut', 'rush', 'past', 'eye', 'glu', 'phone', 'midst', 'fastpac', 'world', 'small', 'moment', 'kind', 'often', 'go', 'unnoticedâ€', '”', 'smile', 'stranger', 'help', 'hand', 'groceri', 'nod', 'familiar', 'face', 'quiet', 'fleet', 'interact', 'remind', 'us', 'even', 'busiest', 'environ', 'connect', 'alway', 'possibl']\n"
     ]
    }
   ],
   "source": [
    "# Preprocess the text\n",
    "processed_text = preprocess_text(text)\n",
    "print(\"\\nProcessed Text:\\n\", processed_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "334410d6-7c30-42b9-8d05-ac8cd855df72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Lemmatized Text:\n",
      " ['bustl', 'citi', 'peopl', 'move', 'daili', 'routin', 'often', 'unawar', 'world', 'unfold', 'around', 'earli', 'morn', 'coffe', 'shop', 'latenight', 'diner', 'rhythm', 'life', 'continu', 'street', 'vendor', 'call', 'advertis', 'fresh', 'produc', 'handmad', 'good', 'commut', 'rush', 'past', 'eye', 'glu', 'phone', 'midst', 'fastpac', 'world', 'small', 'moment', 'kind', 'often', 'go', 'unnoticedâ€', '”', 'smile', 'stranger', 'help', 'hand', 'groceri', 'nod', 'familiar', 'face', 'quiet', 'fleet', 'interact', 'remind', 'u', 'even', 'busiest', 'environ', 'connect', 'alway', 'possibl']\n"
     ]
    }
   ],
   "source": [
    "# Apply lemmatization to the processed text\n",
    "lemmatized_text = lemmatize_words(processed_text)\n",
    "print(\"\\nLemmatized Text:\\n\", lemmatized_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c9c5fa7-95a7-46a5-b4af-111e87578743",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
